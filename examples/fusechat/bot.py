#
# Copyright (c) 2024â€“2025, Daily
#
# SPDX-License-Identifier: BSD 2-Clause License
#

"""Pipecat Quickstart Example.

The example runs a simple voice AI bot that you can connect to using your
browser and speak with it. You can also deploy this bot to Pipecat Cloud.

Required AI services:
- Deepgram (Speech-to-Text)
- OpenAI (LLM)
- Cartesia (Text-to-Speech)

Run the bot using::

    uv run bot.py
"""

import os
import certifi  

os.environ['SSL_CERT_FILE'] = certifi.where()
os.environ['REQUESTS_CA_BUNDLE'] = certifi.where()

from dotenv import load_dotenv
from loguru import logger

print("ğŸš€ Starting Pipecat bot...")
print("â³ Loading models and imports (20 seconds, first run only)\n")

logger.info("Loading Local Smart Turn Analyzer V3...")
from pipecat.audio.turn.smart_turn.local_smart_turn_v3 import LocalSmartTurnAnalyzerV3

logger.info("âœ… Local Smart Turn Analyzer V3 loaded")
logger.info("Loading Silero VAD model...")
from pipecat.audio.vad.silero import SileroVADAnalyzer

logger.info("âœ… Silero VAD model loaded")

from pipecat.audio.vad.vad_analyzer import VADParams
from pipecat.frames.frames import LLMRunFrame

logger.info("Loading pipeline components...")
from pipecat.pipeline.pipeline import Pipeline
from pipecat.pipeline.parallel_pipeline import ParallelPipeline
from pipecat.pipeline.runner import PipelineRunner
from pipecat.pipeline.task import PipelineParams, PipelineTask
from pipecat.processors.aggregators.llm_context import LLMContext
from pipecat.processors.aggregators.llm_response_universal import LLMContextAggregatorPair
from pipecat.processors.frameworks.rtvi import RTVIConfig, RTVIObserver, RTVIProcessor
from pipecat.runner.types import RunnerArguments
from pipecat.runner.utils import create_transport
from pipecat.services.qwen.tts import DashScopeTTSService
from pipecat.services.qwen.stt import DashScopeSTTService
from pipecat.services.qwen.tts_realtime import DashScopeTTSRealTimeService
from pipecat.services.qwen.llm import QwenLLMService
from pipecat.services.openai.base_llm import BaseOpenAILLMService
# from pipecat.services.cartesia.tts import CartesiaTTSService
# from pipecat.services.deepgram.stt import DeepgramSTTService
# from pipecat.services.openai.llm import OpenAILLMService
from pipecat.transports.base_transport import BaseTransport, TransportParams
from pipecat.transports.daily.transport import DailyParams

import random
# random.seed(42)

logger.info("âœ… All components loaded successfully!")

load_dotenv(override=True)

VALID_VOICES = {
    # å¸¸ç”¨æ¨è
    "cherry": "Cherry",       # èŠŠæ‚¦ - é˜³å…‰ç§¯æã€äº²åˆ‡è‡ªç„¶å°å§å§
    "serena": "Serena",       # è‹ç‘¶ - æ¸©æŸ”å°å§å§
    "ethan": "Ethan",         # æ™¨ç…¦ - æ ‡å‡†æ™®é€šè¯ï¼Œé˜³å…‰æš–ç”·
    
    # ç‰¹è‰²éŸ³è‰²
    # "chelsie": "Chelsie",     # åƒé›ª - äºŒæ¬¡å…ƒè™šæ‹Ÿå¥³å‹
    # "momo": "Momo",           # èŒ‰å…” - æ’’å¨‡ææ€ª
    # "vivian": "Vivian",       # åä¸‰ - æ‹½æ‹½çš„å°æš´èº
    # "moon": "Moon",           # æœˆç™½ - ç‡æ€§å¸…æ°”
    # "maia": "Maia",           # å››æœˆ - çŸ¥æ€§ä¸æ¸©æŸ”
    # "kai": "Kai",             # å‡¯ - è€³æœµSPA
    # "nofish": "Nofish",       # ä¸åƒé±¼ - ä¸ä¼šç¿˜èˆŒéŸ³çš„è®¾è®¡å¸ˆ
    # "bella": "Bella",         # èŒå® - å–é…’ä¸æ‰“é†‰æ‹³çš„å°èè‰
    # "jennifer": "Jennifer",   # è©¹å¦®å¼— - ç”µå½±è´¨æ„Ÿç¾è¯­
    # "ryan": "Ryan",           # ç”œèŒ¶ - èŠ‚å¥æ‹‰æ»¡
    # "katerina": "Katerina",   # å¡æ·ç³å¨œ - å¾¡å§éŸ³è‰²
    # "aiden": "Aiden",         # è‰¾ç™» - ç¾è¯­å¤§ç”·å­©
    # "eldric": "Eldric Sage",  # æ²§æ˜å­ - æ²‰ç¨³ç¿æ™ºè€è€…
    # "mia": "Mia",             # ä¹–å°å¦¹ - æ¸©é¡ºå¦‚æ˜¥æ°´
    # "mochi": "Mochi",         # æ²™å°å¼¥ - èªæ˜ä¼¶ä¿å°å¤§äºº
    # "bellona": "Bellona",     # ç‡•é“®èº - å£°éŸ³æ´ªäº®ï¼Œæ±Ÿæ¹–æ°”
    # "vincent": "Vincent",     # ç”°å” - æ²™å“‘çƒŸå—“
    # "bunny": "Bunny",         # èŒå°å§¬ - èŒå±æ€§çˆ†æ£š
    # "neil": "Neil",           # é˜¿é—» - ä¸“ä¸šæ–°é—»ä¸»æŒ
    # "elias": "Elias",         # å¢¨è®²å¸ˆ - ä¸¥è°¨å™äº‹
    # "arthur": "Arthur",       # å¾å¤§çˆ· - è´¨æœ´æ—±çƒŸå—“
    # "nini": "Nini",           # é‚»å®¶å¦¹å¦¹ - è½¯ç³¯ç”œç¾
    # "ebona": "Ebona",         # è¯¡å©†å©† - ææ€–ç«¥å¹´é˜´å½±
    # "seren": "Seren",         # å°å©‰ - åŠ©çœ å£°çº¿
    # "pip": "Pip",             # é¡½å±å°å­© - è°ƒçš®æ£è›‹
    # "stella": "Stella",       # å°‘å¥³é˜¿æœˆ - è¿·ç³Šå°‘å¥³/æ­£ä¹‰æˆ˜å£«
    
    # # æ–¹è¨€ä¸å¤–è¯­ç‰¹è‰²
    # "bodega": "Bodega",       # åšå¾·åŠ  - è¥¿ç­ç‰™å¤§å”
    # "sonrisa": "Sonrisa",     # ç´¢å°¼è - æ‹‰ç¾å¤§å§
    # "alek": "Alek",           # é˜¿åˆ—å…‹ - æˆ˜æ–—æ°‘æ—
    # "dolce": "Dolce",         # å¤šå°”åˆ‡ - æ„å¤§åˆ©å¤§å”
    # "sohee": "Sohee",         # ç´ ç†™ - éŸ©å›½æ¬§å°¼
    # "ono": "Ono Anna",        # å°é‡æ - é¬¼çµç²¾æ€ª
    # "lenn": "Lenn",           # è±æ© - å¾·å›½é’å¹´
    # "emilien": "Emilien",     # åŸƒç±³å°”å®‰ - æ³•å›½å¤§å“¥å“¥
    # "andre": "Andre",         # å®‰å¾·é›· - æ²‰ç¨³ç”·ç”Ÿ
    # "radio": "Radio Gol",     # è¶³çƒè¯—äºº - è§£è¯´é£
    
    # # ä¸­å›½æ–¹è¨€
    # "jada": "Jada",           # ä¸Šæµ·-é˜¿ç
    # "dylan": "Dylan",         # åŒ—äº¬-æ™“ä¸œ
    # "li": "Li",               # å—äº¬-è€æ
    # "marcus": "Marcus",       # é™•è¥¿-ç§¦å·
    # "roy": "Roy",             # é—½å—-é˜¿æ° (å°æ™®)
    # "peter": "Peter",         # å¤©æ´¥-æå½¼å¾— (ç›¸å£°é£)
    # "sunny": "Sunny",         # å››å·-æ™´å„¿
    # "eric": "Eric",           # å››å·-ç¨‹å·
    # "rocky": "Rocky",         # ç²¤è¯­-é˜¿å¼º
    # "kiki": "Kiki",           # ç²¤è¯­-é˜¿æ¸…
}

async def run_2bots(transport: BaseTransport, runner_args: RunnerArguments):
    logger.info(f"Starting bot")

    api_key = "sk-"

    params=BaseOpenAILLMService.InputParams(
        # frequency_penalty=0.0,
        # presence_penalty=0.0,
        seed=42,
        temperature=0.7,
        top_p=0.95,
        max_tokens=1024,
        max_completion_tokens=1024,
        # service_tier="standard",
        extra={}
    )

    # stt = DeepgramSTTService(api_key=os.getenv("DEEPGRAM_API_KEY"))

    stt = DashScopeSTTService(
        api_key=api_key,
        model="qwen3-asr-flash-2025-09-08",
        # language=Language.ZH,
        prompt="" # å¯é€‰
    )

    tts = DashScopeTTSService(
        api_key=api_key,
        voice="Serena",  # British Reading Lady
        model="qwen3-tts-flash-2025-11-27",
        sample_rate=24000
    )


# 
    llm = QwenLLMService(api_key=api_key,model='deepseek-v3',params=params)

    messages = [
        {
            "role": "system",
            "content": "You are FuseChat-3.0, created by Sun Yat-sen University Language Intelligence Technology (SLIT) AI Lab.",
        },
    ]

    context = LLMContext(messages)
    context_aggregator = LLMContextAggregatorPair(context)

    context2 = LLMContext(messages)
    context_aggregator2 = LLMContextAggregatorPair(context2)

    rtvi = RTVIProcessor(config=RTVIConfig(config=[]))


    tts2 = DashScopeTTSService(
        api_key=api_key,
        voice="Ethan",  # British Reading Lady
        model="qwen3-tts-flash-2025-11-27",
        sample_rate=24000
    )
    
    llm2 = QwenLLMService(api_key=api_key,model='qwen-max',params=params)

    pipeline = Pipeline(
        [
            transport.input(),  # Transport user input
            rtvi,  # RTVI processor
            stt,
            ParallelPipeline( 
                # Agent 1:
                [
                    context_aggregator.user(),  # User responses
                    llm,  # LLM
                    tts,  # TTS
                    transport.output(),  # Transport bot output
                ],
                # Agent 2: 
                [
                    context_aggregator2.user(),  # User responses
                    llm2,  # LLM
                    tts2,  # TTS
                    transport.output(),  # Transport bot output
                ]
            ),
            context_aggregator.assistant(),  # Assistant spoken responses
            context_aggregator2.assistant(),  # Assistant spoken responses
        ]
    )
    task = PipelineTask(
        pipeline,
        params=PipelineParams(
            enable_metrics=True,
            enable_usage_metrics=True,
        ),
        observers=[RTVIObserver(rtvi)],
    )

    @transport.event_handler("on_client_connected")
    async def on_client_connected(transport, client):
        logger.info(f"Client connected")
        pass
        # Kick off the conversation.
        # messages.append({"role": "system", "content": "Say hello and briefly introduce yourself."})
        # await task.queue_frames([LLMRunFrame()])

    @transport.event_handler("on_client_disconnected")
    async def on_client_disconnected(transport, client):
        logger.info(f"Client disconnected")
        await task.cancel()

    runner = PipelineRunner(handle_sigint=runner_args.handle_sigint)

    await runner.run(task)

async def run_bot(transport: BaseTransport, runner_args: RunnerArguments):
    logger.info(f"Starting bot")

    api_key = "sk-"

    # api_key = "sk-"

    params=BaseOpenAILLMService.InputParams(
        # frequency_penalty=0.0,
        # presence_penalty=0.0,
        seed=42,
        temperature=0.7,
        top_p=0.95,
        max_tokens=2048,
        max_completion_tokens=768,
        # service_tier="standard",
        extra={}
    )

    # stt = DeepgramSTTService(api_key=os.getenv("DEEPGRAM_API_KEY"))

    stt = DashScopeSTTService(
        api_key=api_key,
        model="qwen3-asr-flash-2025-09-08",
        # language=Language.ZH,
        prompt="" # å¯é€‰
    )

    # tts = DashScopeTTSService(
    #     api_key=api_key,
    #     voice="Serena",  # British Reading Lady
    #     model="qwen3-tts-flash-2025-11-27",
    #     sample_rate=24000
    # )

    tts = DashScopeTTSService(
        api_key=api_key,
        voice=random.choice(list(VALID_VOICES.keys())),  # British Reading Lady
        model="qwen3-tts-flash-2025-11-27",
        sample_rate=24000
    )

    tts_realtime = DashScopeTTSRealTimeService(
        api_key=api_key,
        voice=random.choice(list(VALID_VOICES.keys())),  # British Reading Lady
        model="qwen3-tts-flash-realtime-2025-11-27",
        sample_rate=24000
    )


    llm = QwenLLMService(api_key=api_key,model='qwen2.5-7b-instruct',params=params)

    # VERIFIER_HOST="22.8.148.33"
    # VERIFIER_PORT="23547"
    # API_BASE="http://${VERIFIER_HOST}:${VERIFIER_PORT}/v1"

    
    # VERIFIER_HOST="22.8.158.84"
    # VERIFIER_PORT="23547"
    # API_BASE=f"http://${VERIFIER_HOST}:${VERIFIER_PORT}/v1"

    # llm = BaseOpenAILLMService(base_url="http://localhost:11434/v1/", api_key="ollama",model='FuseChat-3.0-1B',params=params)
    # llm = BaseOpenAILLMService(api_key=API_BASE,model='FuseChat-3.0',params=params)
    # llm = BaseOpenAILLMService(base_url=API_BASE, api_key="EMPTY",model='gpt-oss-120b',params=params)

    # messages = [
    #     {
    #         "role": "system",
    #         "content": "You are FuseChat-3.0, created by Sun Yat-sen University Language Intelligence Technology (SLIT) AI Lab.",
    #     },
    # ]

    messages = [
        {
            "role": "system",
            "content": "You are FuseChat-3.0, created by Shenzhen Loop Area Institute (æ·±åœ³æ²³å¥—å­¦é™¢). Your response should not contain Markdown syntax or emojis.",
        },
    ]

    context = LLMContext(messages)
    context_aggregator = LLMContextAggregatorPair(context)

    rtvi = RTVIProcessor(config=RTVIConfig(config=[]))


    pipeline = Pipeline(
        [
            transport.input(),  # Transport user input
            rtvi,  # RTVI processor
            stt,
            context_aggregator.user(),  # User responses
            llm,  # LLM
            # ParallelPipeline(
            #     [tts, transport.output()],
            #     [context_aggregator.assistant()]
            # )
            tts_realtime,  # TTS
            transport.output(),  
            context_aggregator.assistant()
        ]
    )

    task = PipelineTask(
        pipeline,
        params=PipelineParams(
            allow_interruptions=False,  # å…³é”®ä¿®æ”¹ï¼šç¦ç”¨æ‰“æ–­åŠŸèƒ½
            enable_metrics=True,
            enable_usage_metrics=True,
        ),
        observers=[RTVIObserver(rtvi)],
    )

    @transport.event_handler("on_client_connected")
    async def on_client_connected(transport, client):
        logger.info(f"Client connected")
        pass
        # Kick off the conversation.
        # messages.append({"role": "system", "content": "Say hello and briefly introduce yourself."})
        # await task.queue_frames([LLMRunFrame()])

    @transport.event_handler("on_client_disconnected")
    async def on_client_disconnected(transport, client):
        logger.info(f"Client disconnected")
        await task.cancel()

    runner = PipelineRunner(handle_sigint=runner_args.handle_sigint)

    await runner.run(task)


async def bot(runner_args: RunnerArguments):
    """Main bot entry point for the bot starter."""

    transport_params = {
        "daily": lambda: DailyParams(
            audio_in_enabled=True,
            audio_out_enabled=True,
            video_in_enabled=False,      # Disable video input
            video_out_enabled=False, 
            audio_out_sample_rate=24000,
            vad_analyzer=SileroVADAnalyzer(params=VADParams(stop_secs=0.2)),
            turn_analyzer=LocalSmartTurnAnalyzerV3(),
        ),
        "webrtc": lambda: TransportParams(
            audio_in_enabled=True,
            audio_out_enabled=True,
            video_in_enabled=False,      # Disable video input
            video_out_enabled=False, 
            audio_out_sample_rate=24000,
            vad_analyzer=SileroVADAnalyzer(params=VADParams(stop_secs=0.2)),
            turn_analyzer=LocalSmartTurnAnalyzerV3(),
        ),
    }

    transport = await create_transport(runner_args, transport_params)

    await run_bot(transport, runner_args)


if __name__ == "__main__":

    from pipecat.runner.run import main

    main()
    logger.info(f"Starting bot")
